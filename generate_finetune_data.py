import os
import json
import re
import pandas as pd # On ajoute pandas pour lire les CSV
from langchain_ollama import ChatOllama

# --- CONFIGURATION ---
DATA_DIR = "data"
OUTPUT_FILE = "dataset_ensaj.json"
MODEL_NAME = "llama3.2"

# Initialisation du mod√®le local
llm = ChatOllama(model=MODEL_NAME, temperature=0.7)

def clean_json_text(text):
    """Nettoie la r√©ponse de l'IA pour ne garder que le JSON"""
    match = re.search(r'\[.*\]', text, re.DOTALL)
    if match:
        return match.group(0)
    return text

def generate_qa(text_chunk, source_type="texte"):
    """Demande √† l'IA de cr√©er des Q&A"""
    
    # On adapte un peu le prompt si c'est un tableau (CSV)
    consigne_extra = ""
    if source_type == "csv":
        consigne_extra = "Ce texte provient d'un tableau (CSV). Pose des questions pr√©cises sur les donn√©es (horaires, noms, emails)."

    prompt = f"""
    Tu es un expert charg√© de cr√©er des donn√©es d'entra√Ænement.
    
    TA MISSION :
    Lis le contenu ci-dessous ({source_type}) et invente 2 √† 3 paires de "Instruction" (Question) et "Output" (R√©ponse).
    {consigne_extra}
    
    STYLE OBLIGATOIRE :
    - Question d'un √©tudiant curieux.
    - R√©ponse d'un √©tudiant de l'ENSAJ (style naturel, direct).
    
    FORMAT JSON STRICT :
    [
        {{"instruction": "Question...", "input": "", "output": "R√©ponse..."}},
        {{"instruction": "Question...", "input": "", "output": "R√©ponse..."}}
    ]

    CONTENU SOURCE :
    {text_chunk}
    
    G√©n√®re uniquement le JSON.
    """
    try:
        response = llm.invoke(prompt)
        cleaned = clean_json_text(response.content)
        return json.loads(cleaned)
    except Exception as e:
        # On ignore silencieusement les erreurs de parsing pour ne pas polluer le terminal
        return []

def main():
    print(f"üöÄ D√©marrage de la g√©n√©ration V2 (TXT + CSV)...")
    all_data = []

    if not os.path.exists(DATA_DIR):
        print(f"‚ùå Erreur : Dossier '{DATA_DIR}' introuvable.")
        return

    for filename in os.listdir(DATA_DIR):
        file_path = os.path.join(DATA_DIR, filename)
        content = ""
        source_type = "texte"

        try:
            # 1. Traitement des fichiers TXT
            if filename.endswith(".txt"):
                print(f"üìÑ Lecture de {filename}...")
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

            # 2. Traitement des fichiers CSV (NOUVEAU)
            elif filename.endswith(".csv"):
                print(f"üìä Lecture de {filename}...")
                df = pd.read_csv(file_path)
                # On convertit le tableau en texte pour que l'IA puisse le lire
                content = df.to_string(index=False)
                source_type = "csv"
            
            else:
                continue # On ignore les autres fichiers

            # D√©coupage et G√©n√©ration
            if content:
                # On d√©coupe en morceaux de 1500 caract√®res
                chunks = [content[i:i+1500] for i in range(0, len(content), 1500)]
                
                for i, chunk in enumerate(chunks):
                    print(f"   ‚Ü≥ G√©n√©ration bloc {i+1}/{len(chunks)}...")
                    pairs = generate_qa(chunk, source_type)
                    if pairs:
                        all_data.extend(pairs)
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lecture fichier {filename}: {e}")

    # Sauvegarde
    print(f"\nüíæ Sauvegarde de {len(all_data)} exemples dans {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(all_data, f, indent=4, ensure_ascii=False)
    
    print("‚úÖ PHASE 1 TERMIN√âE ! Vous pouvez v√©rifier le fichier JSON.")

if __name__ == "__main__":
    main()