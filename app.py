import streamlit as st
import sys
import traceback
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import SystemMessage, HumanMessage
import pandas as pd
import os
import re

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Chatbot ENSAJ - RAG Am√©lior√©",
    page_icon="ü§ñ",
    layout="wide"
)

# Initialisation de l'√©tat de session
if "messages" not in st.session_state:
    st.session_state.messages = []
if "faiss_db" not in st.session_state:
    st.session_state.faiss_db = None
if "model" not in st.session_state:
    st.session_state.model = None
if "initialization_error" not in st.session_state:
    st.session_state.initialization_error = None
if "debug_mode" not in st.session_state:
    st.session_state.debug_mode = False

st.title("ü§ñ Chatbot ENSAJ - Syst√®me RAG Am√©lior√©")
st.markdown("Posez vos questions sur l'ENSAJ et obtenez des r√©ponses bas√©es sur les documents disponibles.")

# Fonction pour nettoyer et normaliser le texte
def preprocess_text(text):
    """Nettoie et normalise le texte pour am√©liorer la recherche"""
    # Supprimer les espaces multiples
    text = re.sub(r'\s+', ' ', text)
    # Normaliser la ponctuation
    text = re.sub(r'[\.\,;:\!?]+', ' ', text)
    return text.strip()

# Fonction pour charger les documents
def load_documents():
    """Charge les documents .txt et .csv avec pr√©traitement"""
    docs = []
    data_dir = "data"
    
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        st.warning(f"‚ö†Ô∏è Dossier '{data_dir}' cr√©√©. Ajoutez vos fichiers .txt ou .csv")
        return docs
    
    for filename in os.listdir(data_dir):
        file_path = os.path.join(data_dir, filename)
        
        try:
            # Charger les fichiers .txt
            if filename.endswith(".txt"):
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        # Pr√©traiter le texte
                        content = preprocess_text(content)
                        # Ajouter des m√©tadonn√©es pour am√©liorer la recherche
                        enhanced_content = f"Document: {filename}\n\n{content}"
                        docs.append(enhanced_content)
                        st.success(f"‚úÖ {filename} ({len(content)} caract√®res)")
                    else:
                        st.warning(f"‚ö†Ô∏è {filename} (vide)")
            
            # Charger les fichiers .csv
            elif filename.endswith(".csv"):
                df = pd.read_csv(file_path, encoding="utf-8")
                # Convertir le DataFrame en texte lisible avec plus de contexte
                csv_text = ""
                for col in df.columns:
                    unique_vals = df[col].dropna().unique()
                    if len(unique_vals) > 0:
                        csv_text += f"Colonne {col}: {', '.join(map(str, unique_vals[:10]))}\n"
                
                if len(csv_text.strip()) > 0:
                    enhanced_content = f"Fichier CSV: {filename}\nColonnes: {', '.join(df.columns)}\n\nDonn√©es:\n{csv_text}"
                    docs.append(enhanced_content)
                    st.success(f"‚úÖ {filename} ({len(df)} lignes, {len(df.columns)} colonnes)")
                else:
                    st.warning(f"‚ö†Ô∏è {filename} (vide)")
        
        except Exception as e:
            st.error(f"‚ùå {filename}: {str(e)}")
    
    return docs

# Fonction RAG am√©lior√©e
def ask_question(query):
    try:
        if not st.session_state.faiss_db:
            return "‚ùå Le syst√®me RAG n'est pas pr√™t."
        
        # Recherche √©tendue avec plus de chunks
        results = st.session_state.faiss_db.similarity_search(query, k=8)  # Augment√© de 4 √† 8
        
        # Debug: afficher les chunks r√©cup√©r√©s
        if st.session_state.debug_mode:
            st.sidebar.subheader("üîç Debug - Chunks r√©cup√©r√©s")
            for i, doc in enumerate(results):
                st.sidebar.write(f"**Chunk {i+1}:** {doc.page_content[:150]}...")
        
        context = "\n\n".join([doc.page_content for doc in results])
        
        # Prompt am√©lior√© pour mieux utiliser le contexte
        system_prompt = """
Tu es un assistant expert sp√©cialis√© sur l'ENSAJ (√âcole Nationale des Sciences Appliqu√©es d'El Jadida).

INSTRUCTIONS CRITIQUES:
1. Analyse TR√àS ATTENTIVEMENT le contexte fourni
2. Si l'information exacte n'est pas trouv√©e, cherche des informations PARTIELLES ou APPROCH√âES
3. Pour les nombres et statistiques, sois particuli√®rement attentif aux chiffres dans le contexte
4. Si tu trouves des informations similaires mais pas exactes, fais une D√âDUCTION LOGIQUE
5. Ne dis JAMAIS "je ne sais pas" sans avoir minutieusement analys√© chaque partie du contexte

EXEMPLES:
- Si on demande "nombre d'√©l√®ves" et que le contexte dit "1000 √©l√®ves ing√©nieurs", r√©ponds "1000 √©l√®ves ing√©nieurs"
- Si on demande "effectif" et que le contexte dit "environ 1000 √©tudiants", r√©ponds "environ 1000 √©tudiants"
- Si l'information est partielle, mentionne-le: "D'apr√®s les documents, [...]"

R√©ponds en fran√ßais, sois pr√©cis et utile.
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"CONTEXTE √Ä ANALYSER:\n{context}\n\nQUESTION: {query}\n\nR√©ponds en t'appuyant STRICTEMENT sur le contexte fourni.")
        ]
        
        response = st.session_state.model.invoke(messages)
        return response.content
        
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

# Fonction pour tester le syst√®me
def test_system():
    """Teste le syst√®me avec des questions de r√©f√©rence"""
    test_questions = [
        "Combien d'√©l√®ves y a-t-il √† l'ENSAJ?",
        "Quel est l'effectif des √©tudiants?",
        "Nombre d'√©tudiants √† l'ENSAJ"
    ]
    
    st.sidebar.subheader("üß™ Tests syst√®me")
    for question in test_questions:
        if st.sidebar.button(f"Test: {question}"):
            with st.spinner(f"Test: {question}"):
                response = ask_question(question)
                st.sidebar.write(f"**Q:** {question}")
                st.sidebar.write(f"**R:** {response}")

with st.sidebar:
    st.header("‚öôÔ∏è Configuration du syst√®me")
    
    # Mode debug
    st.session_state.debug_mode = st.checkbox("Mode Debug", value=False)
    
    # Initialisation du syst√®me
    if st.session_state.faiss_db is None and st.session_state.initialization_error is None:
        with st.status("Initialisation du syst√®me...", expanded=True) as status:
            try:
                # 1. Charger les documents
                st.write("üìÇ Chargement des documents...")
                docs = load_documents()
                
                if not docs:        
                    raise ValueError("Aucun document charg√©. Ajoutez des fichiers .txt ou .csv dans le dossier 'data'.")    
                
                st.write(f"üìÑ **Documents charg√©s:** {len(docs)}")
                
                # 2. D√©couper le texte avec des param√®tres optimis√©s
                st.write("‚úÇÔ∏è D√©coupage du texte...")
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=400,  # R√©duit pour mieux capturer les informations
                    chunk_overlap=100,  # Augment√© pour √©viter de couper les informations
                    separators=["\n\n", "\n", ". ", "! ", "? ", ", ", " ", ""]
                )
                chunks = splitter.create_documents(docs)
                st.write(f"üìÑ **Nombre de chunks:** {len(chunks)}")
                
                # 3. Embeddings + FAISS
                st.write("üî§ Initialisation des embeddings...")
                embeddings = OllamaEmbeddings(model="nomic-embed-text")
                test_embedding = embeddings.embed_query("√©tudiants ENSAJ effectif")
                st.write(f"‚úÖ **Dimension des embeddings:** {len(test_embedding)}")
                
                st.write("üóÇÔ∏è Cr√©ation de la base vectorielle FAISS...")
                st.session_state.faiss_db = FAISS.from_documents(chunks, embeddings)
                st.success("‚úÖ Base FAISS cr√©√©e!")
                
                # 4. Mod√®le LLM
                st.write("üß† Initialisation du mod√®le...")
                st.session_state.model = ChatOllama(
                    model="mistral",
                    temperature=0.1
                )
                # Test du mod√®le
                test_response = st.session_state.model.invoke([
                    HumanMessage(content="Test: Bonjour")
                ])
                st.success("‚úÖ Mod√®le initialis√©!")
                
                status.update(label="‚úÖ Syst√®me pr√™t!", state="complete", expanded=False)
                
            except Exception as e:
                error_msg = f"‚ùå Erreur d'initialisation:\n{str(e)}"
                st.session_state.initialization_error = error_msg
                st.error(error_msg)
                status.update(label="‚ùå Erreur d'initialisation", state="error")
    
    # Afficher l'erreur d'initialisation si elle existe
    if st.session_state.initialization_error:
        st.error("Le syst√®me n'a pas pu s'initialiser. V√©rifiez la console pour plus de d√©tails.")
    
    # Statistiques
    st.divider()
    st.subheader("üìà Statistiques")
    if st.session_state.faiss_db:
        st.success("‚úÖ Syst√®me RAG op√©rationnel")
    else:
        st.warning("‚è≥ Initialisation en cours...")
    st.write(f"üí¨ Messages: {len(st.session_state.messages)}")
    
    # Boutons d'action
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üóëÔ∏è Effacer l'historique"):
            st.session_state.messages = []
            st.rerun()
    with col2:
        if st.button("üîÑ Rafra√Æchir"):
            st.session_state.faiss_db = None
            st.session_state.initialization_error = None
            st.rerun()
    
    # Tests syst√®me
    if st.session_state.faiss_db:
        test_system()

# Section principale de chat
if st.session_state.faiss_db is not None:
    # Affichage de l'historique
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Suggestions de questions
    if len(st.session_state.messages) == 0:
        st.info("üí° **Suggestions de questions:** Combien d'√©l√®ves √† l'ENSAJ? Quelles fili√®res? Informations sur les clubs?")
    
    # Input utilisateur
    if prompt := st.chat_input("Posez votre question sur l'ENSAJ..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("üîç Recherche dans les documents..."):
                response = ask_question(prompt)
            st.markdown(response)
        
        st.session_state.messages.append({"role": "assistant", "content": response})
else:
    if st.session_state.initialization_error:
        st.error("‚ùå Le syst√®me rencontre des probl√®mes d'initialisation. V√©rifiez les documents dans le dossier 'data'.")
    else:
        st.info("‚è≥ Initialisation du syst√®me en cours...")

# Footer avec informations
st.sidebar.divider()
st.sidebar.caption("ü§ñ Chatbot ENSAJ RAG v2.0 - Syst√®me am√©lior√©")
