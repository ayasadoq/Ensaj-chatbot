# Importation des biblioth√®ques n√©cessaires
import streamlit as st  # Framework pour cr√©er des applications web
import sys  # Acc√®s aux fonctionnalit√©s syst√®me
import traceback  # Pour le d√©bogage des exceptions
from langchain_ollama import OllamaEmbeddings, ChatOllama  # Int√©gration avec Ollama pour les embeddings et le chat
from langchain_text_splitters import RecursiveCharacterTextSplitter  # D√©coupage intelligent du texte
from langchain_community.vectorstores import FAISS  # Base de donn√©es vectorielle pour la recherche
from langchain_core.messages import SystemMessage, HumanMessage  # Messages pour structurer les conversations
import pandas as pd  # Manipulation de donn√©es tabulaires
import os  # Interactions avec le syst√®me de fichiers
import json  # Traitement de donn√©es JSON

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Chatbot ENSAJ - RAG Am√©lior√©",  # Titre de l'onglet du navigateur
    page_icon="ü§ñ",  # Ic√¥ne de l'application
    layout="wide"  # Utilisation de toute la largeur de la page
)

# Initialisation des variables de session pour persister l'√©tat entre les interactions
if "messages" not in st.session_state:
    st.session_state.messages = []  # Stocke l'historique de la conversation
if "faiss_db" not in st.session_state:
    st.session_state.faiss_db = None  # Stocke la base de donn√©es vectorielle
if "model" not in st.session_state:
    st.session_state.model = None  # Stocke le mod√®le de langage
if "initialization_error" not in st.session_state:
    st.session_state.initialization_error = None  # Stocke les erreurs d'initialisation
if "debug_mode" not in st.session_state:
    st.session_state.debug_mode = False  # Active/d√©sactive le mode d√©bogage
if "retrieval_context" not in st.session_state:
    st.session_state.retrieval_context = []  # Stocke le contexte r√©cup√©r√© pour debug

# Interface utilisateur principale
st.title("ü§ñ Chatbot ENSAJ - Syst√®me RAG Am√©lior√©")
st.markdown("Posez vos questions sur l'ENSAJ et obtenez des r√©ponses bas√©es sur les documents disponibles.")

def load_documents():
    """
    Charge et pr√©pare les documents texte et CSV depuis le dossier 'data'
    
    Returns:
        list: Liste des contenus textuels des documents
    """
    docs = []  # Liste pour stocker tous les contenus de documents
    data_dir = "data"  # Dossier contenant les donn√©es
    
    # Cr√©ation du dossier s'il n'existe pas
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        st.warning(f"‚ö†Ô∏è Dossier '{data_dir}' cr√©√©. Ajoutez vos fichiers .txt ou .csv")
        return docs  # Retourne une liste vide si pas de documents
    
    # Parcours de tous les fichiers dans le dossier data
    for filename in os.listdir(data_dir):
        file_path = os.path.join(data_dir, filename)
        
        try:
            # Traitement des fichiers texte (.txt)
            if filename.endswith(".txt"):
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()  # Lecture et nettoyage du contenu
                    if content:
                        # Conservation de toute la ponctuation (importante pour le sens)
                        docs.append(content)
                        st.success(f"‚úÖ {filename}")  # Confirmation du chargement
                    else:
                        st.warning(f"‚ö†Ô∏è {filename} (vide)")  # Avertissement pour fichier vide
            
            # Traitement des fichiers CSV (.csv)
            elif filename.endswith(".csv"):
                # Lecture du fichier CSV avec pandas
                df = pd.read_csv(file_path, encoding="utf-8")
                
                # M√©thode 1: Conversion compl√®te en texte
                csv_full_text = df.to_string()
                
                # M√©thode 2: Cr√©ation d'un r√©sum√© structur√©
                summary_parts = [f"=== Fichier: {filename} ==="]
                summary_parts.append(f"Colonnes: {', '.join(df.columns)}")  # Liste des colonnes
                summary_parts.append(f"Nombre de lignes: {len(df)}")  # Nombre d'enregistrements
                summary_parts.append("\nDONN√âES COMPL√àTES:\n")
                summary_parts.append(csv_full_text)  # Donn√©es compl√®tes
                
                # Combinaison de toutes les parties
                combined_content = "\n".join(summary_parts)
                docs.append(combined_content)
                st.success(f"‚úÖ {filename} ({len(df)} lignes)")  # Confirmation avec stats
        
        except Exception as e:
            st.error(f"‚ùå {filename}: {str(e)}")  # Affichage des erreurs de traitement
    
    return docs  # Retourne tous les documents charg√©s

def ask_question(query):
    """
    Traite une question en utilisant le syst√®me RAG (Retrieval-Augmented Generation)
    
    Args:
        query (str): La question pos√©e par l'utilisateur
        
    Returns:
        str: La r√©ponse g√©n√©r√©e par le mod√®le
    """
    try:
        # V√©rification que le syst√®me est pr√™t
        if not st.session_state.faiss_db or not st.session_state.model:
            return "‚ùå Le syst√®me RAG n'est pas pr√™t."
        
        # R√âCUP√âRATION AM√âLIOR√âE: Recherche de contexte pertinent
        # Augmentation du nombre de r√©sultats pour plus de contexte
        results = st.session_state.faiss_db.similarity_search(query, k=10)
        
        # D√©duplication pour √©viter les r√©p√©titions
        unique_results = []
        seen_content = set()  # Pour suivre les contenus d√©j√† vus
        for doc in results:
            if doc.page_content.strip() not in seen_content:
                unique_results.append(doc)
                seen_content.add(doc.page_content.strip())
        
        # Affichage debug du contexte r√©cup√©r√©
        if st.session_state.debug_mode:
            st.sidebar.subheader("üîç Debug - Contexte r√©cup√©r√©")
            for i, doc in enumerate(unique_results[:5]):  # Limit√© aux 5 premiers
                preview = doc.page_content[:200].replace('\n', ' ')  # Aper√ßu tronqu√©
                st.sidebar.write(f"**[{i+1}]** {preview}...")
        
        # Combinaison de tous les contextes pertinents
        context = "\n\n---\n\n".join([doc.page_content for doc in unique_results])
        
        # Sauvegarde pour le d√©bogage (limit√© aux 500 premiers caract√®res)
        st.session_state.retrieval_context = context[:500]
        
        # PROMPT AM√âLIOR√â: Instructions strictes pour le mod√®le
        system_prompt = """Tu es un assistant sp√©cialis√© sur l'ENSAJ.

R√àGLES ABSOLUES:
1. Tu DOIS r√©pondre UNIQUEMENT avec les informations du contexte
2. Si une information n'est pas dans le contexte, tu dis: "Les documents ne contiennent pas cette information"
3. Cite TOUJOURS les sources (ex: "D'apr√®s le document X...")
4. Pour les nombres/dates/noms, sois EXACTEMENT pr√©cis
5. R√©ponds EN FRAN√áAIS
6. Si on demande un nombre et que tu le vois, r√©ponds le nombre EXACTEMENT
7. Ne fais JAMAIS de d√©ductions ou d'hypoth√®ses
8. Cite les portions pertinentes du contexte si n√©cessaire

Format de r√©ponse:
- Question clairement comprise
- R√©ponse directe et pr√©cise du contexte
- Source/Document d'o√π vient l'info"""
        
        # Construction des messages pour le mod√®le
        messages = [
            SystemMessage(content=system_prompt),  # Instructions syst√®me
            HumanMessage(content=f"""CONTEXTE DISPONIBLE:
{context}

QUESTION: {query}

R√©ponds UNIQUEMENT avec ce que tu trouves dans le contexte ci-dessus.""")
        ]
        
        # Appel au mod√®le pour g√©n√©rer la r√©ponse
        response = st.session_state.model.invoke(messages)
        return response.content  # Retourne le contenu de la r√©ponse
        
    except Exception as e:
        # Gestion des erreurs avec message d'information
        return f"‚ùå Erreur: {str(e)}\n\nV√©rifiez que Ollama est lanc√© et que le mod√®le mistral est t√©l√©charg√©."

# =============================================================================
# BARRE LAT√âRALE - CONFIGURATION ET CONTR√îLES
# =============================================================================
with st.sidebar:
    st.header("‚öôÔ∏è Configuration du syst√®me")
    
    # Option pour activer le mode d√©bogage
    st.session_state.debug_mode = st.checkbox("üêõ Mode Debug (voir le contexte r√©cup√©r√©)", value=False)
    
    # Initialisation du syst√®me (si pas d√©j√† fait)
    if st.session_state.faiss_db is None and st.session_state.initialization_error is None:
        with st.status("Initialisation du syst√®me...", expanded=True) as status:
            try:
                # √âtape 1: Chargement des documents
                st.write("üìÇ Chargement des documents...")
                docs = load_documents()
                
                # V√©rification qu'il y a des documents
                if not docs:        
                    raise ValueError("‚ùå Aucun document. Ajoutez des fichiers .txt ou .csv dans le dossier 'data'")    
                
                st.write(f"‚úÖ {len(docs)} document(s) charg√©(s)")
                
                # √âtape 2: D√©coupage du texte en chunks
                st.write("‚úÇÔ∏è D√©coupage du texte...")
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=800,  # Taille optimale pour pr√©server le contexte
                    chunk_overlap=200,  # Chevauchement pour √©viter de couper les informations
                    separators=["\n\n", "\n", ". ", " "]  # Ordre de priorit√© pour la d√©coupe
                )
                chunks = splitter.create_documents(docs)
                st.write(f"‚úÖ {len(chunks)} chunks cr√©√©s")
                
                # √âtape 3: Initialisation des embeddings
                st.write("üî§ Initialisation des embeddings...")
                embeddings = OllamaEmbeddings(model="nomic-embed-text")
                # Test pour v√©rifier que les embeddings fonctionnent
                test_embedding = embeddings.embed_query("ENSAJ √©tudiants information")
                st.write(f"‚úÖ Dimension: {len(test_embedding)}")
                
                # √âtape 4: Cr√©ation de la base vectorielle FAISS
                st.write("üóÇÔ∏è Cr√©ation de la base vectorielle...")
                st.session_state.faiss_db = FAISS.from_documents(chunks, embeddings)
                st.success("‚úÖ Base FAISS cr√©√©e!")
                
                # √âtape 5: Initialisation du mod√®le de langage
                st.write("üß† Initialisation du mod√®le Mistral...")
                st.session_state.model = ChatOllama(
                    model="mistral",
                    temperature=0.1  # Faible temp√©rature pour des r√©ponses d√©terministes
                )
                st.success("‚úÖ Mod√®le pr√™t!")
                
                status.update(label="‚úÖ Syst√®me pr√™t!", state="complete", expanded=False)
                
            except Exception as e:
                # Gestion des erreurs d'initialisation
                error_msg = f"‚ùå Erreur:\n{str(e)}"
                st.session_state.initialization_error = error_msg
                st.error(error_msg)
                status.update(label="‚ùå Erreur", state="error")
    
    # Affichage des erreurs d'initialisation
    if st.session_state.initialization_error:
        st.error(st.session_state.initialization_error)
    
    st.divider()
    st.subheader("üìà √âtat")
    
    # Indicateur d'√©tat du syst√®me
    if st.session_state.faiss_db:
        st.success("‚úÖ Syst√®me op√©rationnel")
    else:
        st.warning("‚è≥ Initialisation...")
    
    st.write(f"üí¨ Messages: {len(st.session_state.messages)}")
    
    # Boutons de contr√¥le
    if st.button("üóëÔ∏è Effacer l'historique"):
        st.session_state.messages = []
        st.rerun()  # Recharge la page
    
    if st.button("üîÑ R√©initialiser le syst√®me"):
        st.session_state.faiss_db = None
        st.session_state.initialization_error = None
        st.rerun()  # Recharge la page
    
    # Affichage du contexte en mode debug
    if st.session_state.debug_mode and st.session_state.retrieval_context:
        st.divider()
        st.subheader("üìù Dernier contexte")
        st.text_area("Contexte:", value=st.session_state.retrieval_context, height=150, disabled=True)

# =============================================================================
# SECTION PRINCIPALE - INTERFACE DE CHAT
# =============================================================================
if st.session_state.faiss_db is not None:
    # Affichage de l'historique des messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):  # Affiche user ou assistant
            st.markdown(message["content"])
    
    # Message d'accueil si premi√®re utilisation
    if len(st.session_state.messages) == 0:
        st.info("üí° Posez vos questions sur l'ENSAJ. Le chatbot r√©cup√®re les r√©ponses des documents.")
    
    # Saisie de la question par l'utilisateur
    if prompt := st.chat_input("Question..."):
        # Ajout de la question √† l'historique
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # G√©n√©ration et affichage de la r√©ponse
        with st.chat_message("assistant"):
            with st.spinner("üîç Recherche..."):  # Indicateur de progression
                response = ask_question(prompt)
            st.markdown(response)
        
        # Ajout de la r√©ponse √† l'historique
        st.session_state.messages.append({"role": "assistant", "content": response})
else:
    # Message d'erreur si le syst√®me n'est pas initialis√©
    st.error("‚ùå Le syst√®me n'est pas initialis√©. V√©rifiez les erreurs ci-dessus.")

# Pied de page dans la barre lat√©rale
st.sidebar.divider()
st.sidebar.caption("Chatbot ENSAJ RAG v3.0")