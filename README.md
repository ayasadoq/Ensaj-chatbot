# ğŸ¤– ENSAJ Chatbot - SystÃ¨me RAG

Un chatbot intelligent utilisant **Retrieval-Augmented Generation (RAG)** pour rÃ©pondre Ã  vos questions sur l'ENSAJ.

## ğŸ“‹ PrÃ©requis

- **Python 3.8+**
- **Ollama** (pour les modÃ¨les LLM et embeddings)
  - [TÃ©lÃ©charger Ollama](https://ollama.ai)
  - ModÃ¨les requis : `mistral` et `nomic-embed-text`
- **Microphone** (pour la reconnaissance vocale - optionnel)
- **Haut-parleurs** (pour la synthÃ¨se vocale - optionnel)

## ğŸš€ Installation

### 1. Cloner le projet
```bash
git clone https://github.com/ayasadoq/Ensaj-chatbot.git
cd Ensaj-chatbot
```

### 2. CrÃ©er un environnement virtuel Python
```bash
python -m venv ensajenv
```

**Activer l'environnement :**
- **Windows (PowerShell)** :
  ```powershell
  .\ensajenv\Scripts\Activate.ps1
  ```
- **Windows (CMD)** :
  ```cmd
  ensajenv\Scripts\activate.bat
  ```
- **macOS/Linux** :
  ```bash
  source ensajenv/bin/activate
  ```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

## ğŸ”§ Configuration d'Ollama

### 1. DÃ©marrer le service Ollama
```bash
ollama serve
```

### 2. TÃ©lÃ©charger les modÃ¨les requis (dans un autre terminal)
```bash
# TÃ©lÃ©charger le modÃ¨le Mistral (pour les rÃ©ponses)
ollama pull mistral

# TÃ©lÃ©charger le modÃ¨le nomic-embed-text (pour les embeddings)
ollama pull nomic-embed-text
```

VÃ©rifier que les modÃ¨les sont installÃ©s :
```bash
ollama list
```

## ğŸ“ Structure des donnÃ©es

Le dossier `data/` contient vos documents :

```
data/
â”œâ”€â”€ clubs.txt          # Informations sur les clubs
â”œâ”€â”€ Contact.csv        # Contacts (format CSV)
â”œâ”€â”€ emploi_*.csv       # Emplois du temps par filiÃ¨re
â”œâ”€â”€ ensaj.txt          # Informations gÃ©nÃ©rales ENSAJ
â”œâ”€â”€ filiere.txt        # Informations sur les filiÃ¨res
â””â”€â”€ reglement.txt      # RÃ¨glements
```

**Formats supportÃ©s :**
- `.txt` : Fichiers texte bruts
- `.csv` : Fichiers CSV

## ğŸ¤ FonctionnalitÃ©s

- **Chatbot RAG** : Recherche et gÃ©nÃ©ration augmentÃ©e par rÃ©cupÃ©ration
- **Reconnaissance vocale** : Posez vos questions par la voix
- **SynthÃ¨se vocale** : Ã‰coutez les rÃ©ponses du chatbot
- **Recherche sÃ©mantique** : Trouve les documents pertinents avec ChromaDB
- **Historique de conversation** : Conserve l'historique de vos interactions
- **Interface intuitive** : Interface Streamlit facile Ã  utiliser

## â–¶ï¸ Lancer le chatbot

```bash
streamlit run app.py
```

L'application s'ouvrira dans votre navigateur Ã  `http://localhost:8501`

## ğŸ’¬ Utilisation

1. **Interface Streamlit** : L'application se charge automatiquement
2. **Initialisation** : Le systÃ¨me charge vos documents et crÃ©e la base vectorielle FAISS (premiÃ¨re utilisation peut prendre quelques minutes)
3. **Poser une question** : Ã‰crivez votre question dans le champ en bas
4. **Obtenir une rÃ©ponse** : Le chatbot recherche les documents pertinents et gÃ©nÃ¨re une rÃ©ponse basÃ©e sur le contenu

### Exemple de questions
- "Quels sont les clubs disponibles Ã  l'ENSAJ ?"
- "Qui est le responsable de la filiÃ¨re informatique ?"
- "Quels sont les horaires de contact ?"

## ğŸ› ï¸ Architecture

Le systÃ¨me utilise :

- **Streamlit** : Interface web interactive
- **LangChain** : Framework pour les applications LLM
- **Ollama** : ModÃ¨les LLM locaux
- **FAISS** : Base vectorielle pour la recherche sÃ©mantique
- **RecursiveCharacterTextSplitter** : DÃ©coupage intelligent des documents

## ğŸ”„ Flux du systÃ¨me RAG

1. **Chargement** : Les documents (.txt, .csv) sont chargÃ©s
2. **DÃ©coupage** : Texte divisÃ© en chunks (600 caractÃ¨res avec overlap de 80)
3. **Embeddings** : Conversion en vecteurs via `nomic-embed-text`
4. **FAISS** : Indexation vectorielle pour recherche rapide
5. **RequÃªte** : La question est convertie en vecteur
6. **Recherche** : Les 4 chunks les plus pertinents sont trouvÃ©s
7. **GÃ©nÃ©ration** : Mistral gÃ©nÃ¨re une rÃ©ponse basÃ©e sur le contexte

## ğŸ§¹ Gestion

### Effacer l'historique des messages
Cliquez sur le bouton ğŸ—‘ï¸ dans la barre latÃ©rale

### RÃ©initialiser le systÃ¨me
Fermez l'application et relancez `streamlit run app.py`

## âš ï¸ DÃ©pannage

### "Le systÃ¨me RAG n'est pas prÃªt"
- VÃ©rifiez qu'Ollama fonctionne (`ollama serve`)
- VÃ©rifiez que les modÃ¨les sont installÃ©s (`ollama list`)

### "Aucun document chargÃ©"
- CrÃ©ez le dossier `data/` s'il n'existe pas
- Ajoutez des fichiers `.txt` ou `.csv` dans ce dossier

### Erreur de connexion Ã  Ollama
- Assurez-vous qu'Ollama s'exÃ©cute en background
- Port par dÃ©faut : `http://localhost:11434`

### Lenteur de l'application
- C'est normal lors de la premiÃ¨re initialisation (crÃ©ation de la base FAISS)
- Les requÃªtes suivantes sont beaucoup plus rapides

## ğŸ“ Licence

MIT

## ğŸ‘¤ Auteur

[@ayasadoq](https://github.com/ayasadoq)
